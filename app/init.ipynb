{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb1c25b",
   "metadata": {},
   "source": [
    "# ðŸ§  LLM Playground\n",
    "\n",
    "A lightweight environment for experimenting with:\n",
    "\n",
    "- PDF chunking  \n",
    "- Embeddings via Ollama  \n",
    "- pgvector similarity search  \n",
    "- A minimal RAG pipeline  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed302fa5",
   "metadata": {},
   "source": [
    "## ðŸ†Ž Init Environment\n",
    " - Start Environment: .\\venv\\Scripts\\activate\n",
    " - Stop Environment: deactivate\n",
    " - See [readme.md](../README.md) for Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7895b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\env-llm-playground\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init workspace...\n",
      "\n",
      "DB Connection: PG/Vector\n",
      "LLM Model: smollm:360m\n",
      "Embedding Model: mxbai-embed-large\n",
      "\n",
      "âœ“ Ollama LLM Response:  Hey there! How's your day going? I'm glad you're enjoying the playground. Do you have any favorite games or activities to do during recess?\n",
      "âœ“ Ollama Embedding Dimension: 1024\n"
     ]
    }
   ],
   "source": [
    "## Hot-Reload .py Files\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import models # auto-registers all models\n",
    "\n",
    "# Add app directory to path for imports\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "from core.database import Database\n",
    "from core.ollama import Ollama\n",
    "from controllers.RagController import RagController\n",
    "\n",
    "# Test Environment\n",
    "print(\"Init workspace...\\n\")\n",
    "db = Database()\n",
    "if not db.check_connection():\n",
    "    raise SystemExit(\"Database connection failed. Stopping initialization.\")\n",
    "print(\"DB Connection: PG/Vector\")\n",
    "\n",
    "rag = RagController()\n",
    "print(\"LLM Model:\", rag.ollama.llm_model)\n",
    "print(\"Embedding Model:\", rag.ollama.embedding_model)\n",
    "print(\"\\nâœ“ Ollama LLM Response: \", rag.ollama.generate(\"Hello from our Playground!\"))\n",
    "print(\"âœ“ Ollama Embedding Dimension:\", len(rag.ollama.embed(\"hello\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a448bd",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ RAG Controller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f921ea",
   "metadata": {},
   "source": [
    "### Search Embedded Vectors\n",
    "Run a similarity search using the query embedding against stored chunk embeddings.\n",
    "\n",
    " - Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search Query\n",
    "search_query = \"Ich suche einen Softwareentwickler\"\n",
    "result = []\n",
    "\n",
    "try:\n",
    "    results = rag.search(search_query, limit=5)\n",
    "    df = pd.DataFrame(results) \n",
    "    display(df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"âš  Search error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba097c7e",
   "metadata": {},
   "source": [
    "### GET Embedded Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c4d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = rag.get_chunks()\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        \"id\": c.id,\n",
    "        \"document_id\": c.document_id,\n",
    "        \"chunk_index\": c.chunk_index,\n",
    "        \"token_count\": c.token_count,\n",
    "        \"content\": c.content[:200] + \"...\" if len(c.content) > 200 else c.content\n",
    "    }\n",
    "    for c in chunks\n",
    "])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fbbacf",
   "metadata": {},
   "source": [
    "### Create File Embeddings\n",
    " - Chunk PDF\n",
    " - Embed chunks within Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45936e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define File Path\n",
    "file_path = Path(\"./store/resume.pdf\")\n",
    "\n",
    "try:\n",
    "    chunks = rag.chunk_pdf(str(file_path))\n",
    "\n",
    "    if not chunks:\n",
    "        print(\"âš  No chunks were produced. Check PDF content or chunker settings.\")\n",
    "    else:\n",
    "        print(f\"âœ“ Successfully processed PDF into {len(chunks)} chunks\")\n",
    "        print(f\"âœ“ First chunk preview:\\n{chunks[0][:300]}...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"âš  PDF processing error:\", e)\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d0bd86",
   "metadata": {},
   "source": [
    "# ðŸ†Ž Project Initialization\n",
    " - Hard DB Reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8040c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard DB Reset\n",
    "db.set_new_environment()\n",
    "schema = db.show_schema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
